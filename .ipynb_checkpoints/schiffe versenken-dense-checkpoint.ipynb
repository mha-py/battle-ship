{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T10:50:37.751940Z",
     "start_time": "2023-11-01T10:50:36.030472Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import pickle as pkl\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T10:50:39.779546Z",
     "start_time": "2023-11-01T10:50:39.651035Z"
    }
   },
   "outputs": [],
   "source": [
    "# Erstellt August 2020\n",
    "# (c) mha\n",
    "\n",
    "def create_sea(seed=None):\n",
    "    'Creates a sea with random ships on it'\n",
    "    rng = random.Random(seed)\n",
    "    sea = np.zeros((10,10))\n",
    "    #for l in [5, 4, 3, 2]: # Länge\n",
    "    for l in [5,4,3,2]: # Länge\n",
    "        n = 6-l # Anzahl\n",
    "        for _ in range(n):\n",
    "            # Boot mit Länge l platzieren\n",
    "            while True:\n",
    "                t = rng.random() < 0.5\n",
    "                if t: sea = sea.T # Transponieren\n",
    "                px = rng.randint(0, 10-l)\n",
    "                py = rng.randint(0, 9)\n",
    "                if sum(sea[px:px+l,py]) > 0:\n",
    "                    continue\n",
    "                sea[px:px+l, py] = 1\n",
    "                if t: sea = sea.T # Transponieren\n",
    "                break\n",
    "    return sea\n",
    "\n",
    "def create_detection(seed=None, l=5):\n",
    "    'Creates a random detected array (for test purposes)'\n",
    "    rng = random.Random(seed)\n",
    "    det = np.zeros((10,10))\n",
    "    px = rng.randint(0, 10-l)\n",
    "    py = rng.randint(0, 9)\n",
    "    det[px:px+l, py] = 1\n",
    "    \n",
    "    if rng.random() < 0.5: \n",
    "        det = det.T\n",
    "    return det\n",
    "\n",
    "def visualize(sea, detection):\n",
    "    'Erstellt eine Veranschaulichung, 0 bzw. 4 sind detektiertes Wasser bzw. Schiff, 1 und 2 sind undetektiert.'\n",
    "    return sea + sea*detection + 1 - ((1-sea)*detection)\n",
    "\n",
    "def plot_sea(sea, det, ax=None):\n",
    "    if ax is None: ax = plt.gca()\n",
    "    #ax.imshow(visualize(sea, det), vmin=-2, cmap='plasma')\n",
    "    ax.imshow(visualize(sea, det), vmin=-1, vmax=3.15, cmap='cividis')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T10:50:41.978514Z",
     "start_time": "2023-11-01T10:50:40.243599Z"
    }
   },
   "outputs": [],
   "source": [
    "from numba import njit, jit\n",
    "\n",
    "@njit(cache=True)\n",
    "def njit_create_sea():\n",
    "    'Creates a sea with random ships on it'\n",
    "    sea = np.zeros((10,10))\n",
    "    for l in [5,4,3,2]: # Länge\n",
    "        n = 6-l # Anzahl\n",
    "        for _ in range(n):\n",
    "            # Boot mit Länge l platzieren\n",
    "            while True:\n",
    "                t = np.random.rand() < 0.5\n",
    "                if t: sea = sea.T # Transponieren\n",
    "                px = np.random.randint(0, 11-l)\n",
    "                py = np.random.randint(0, 10)\n",
    "                if np.sum(sea[px:px+l,py]) > 0:\n",
    "                    continue\n",
    "                sea[px:px+l, py] = 1\n",
    "                if t: sea = sea.T # Transponieren\n",
    "                break\n",
    "    return sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T10:50:42.861877Z",
     "start_time": "2023-11-01T10:50:42.612970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sea = create_sea(0)\n",
    "#detection = np.zeros((10,10))\n",
    "#detection[4, 0:5] = 1.\n",
    "det = create_detection(l=5, seed=1)\n",
    "###detected = detect(sea, det)\n",
    "\n",
    "plt.imshow(sea*255)\n",
    "plot_sea(sea, det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T10:50:43.519793Z",
     "start_time": "2023-11-01T10:50:43.366147Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_x(sea, det):\n",
    "    'Encodes the visible information to an input to the neural network'\n",
    "    return np.stack([(1-sea)*det, (1-det), sea*det], -1)\n",
    "    \n",
    "\n",
    "def batchgen(size=50):\n",
    "    while True:\n",
    "        xs, ys = [], []\n",
    "        for _ in range(size):\n",
    "            sea = njit_create_sea()\n",
    "            r = np.random.rand()\n",
    "            if r < 0.25:\n",
    "                det = np.random.rand(10,10) < np.random.rand()\n",
    "            elif r < 0.5:\n",
    "                det = np.random.rand(10,10) < 1/30*np.random.rand()\n",
    "            elif r < 0.75:\n",
    "                det = np.random.rand(10,10) < 1/6*np.random.rand()\n",
    "            else:\n",
    "                det = np.random.rand(10,10) < 0.5*np.random.rand()\n",
    "            x = encode_x(sea, det)\n",
    "            xs.append(x)\n",
    "            ys.append(sea.reshape((10,10,1)))\n",
    "        yield np.array(xs), np.array(ys)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T10:50:44.939238Z",
     "start_time": "2023-11-01T10:50:43.720340Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T10:50:47.347038Z",
     "start_time": "2023-11-01T10:50:45.121994Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "relu = torch.nn.ReLU()\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "class bship_nnet(nn.Module):\n",
    "    def __init__(self, n=32):\n",
    "        'BattleShip CNN. More than 1 blocks didnt make a difference.'\n",
    "        super().__init__()\n",
    "        self.body = \\\n",
    "        self.dense1 = nn.Linear(3*10*10, 512)\n",
    "        self.dense2 = nn.Linear(512, 100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # NHWC zu NCHW\n",
    "        x = x.reshape(-1, 3*10*10)\n",
    "        x = relu(self.dense1(x))\n",
    "        x = self.dense2(x)\n",
    "        return x.reshape(-1, 10, 10, 1)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        'Takes a numpy array and give out one, i. e. 10x10 -> 10x10'\n",
    "        x = np2t(x[None,:])\n",
    "        y = self(x)\n",
    "        return t2np(y[0,:,:,0])\n",
    "    \n",
    "    \n",
    "    \n",
    "def augment(x, y):\n",
    "    r = np.random.rand\n",
    "    if r()<0.5:\n",
    "        x, y = x.flip(1), y.flip(1)\n",
    "    if r()<0.5:\n",
    "        x, y = x.flip(2), y.flip(2)\n",
    "    if r()<0.5:\n",
    "        x, y = x.transpose(1,2), y.transpose(1,2)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "net = bship_nnet().cuda();\n",
    "optimizer = torch.optim.Adam(lr=1e-3, params=net.parameters())\n",
    "net.losses = []\n",
    "net.iters = 0\n",
    "\n",
    "teacher = bship_nnet().cuda()\n",
    "teacher.load_state_dict(net.state_dict());\n",
    "teacher.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T11:06:04.205820Z",
     "start_time": "2023-10-29T11:06:03.993916Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for bship_nnet:\n\tMissing key(s) in state_dict: \"body.0.weight\", \"body.0.bias\", \"body.2.weight\", \"body.2.bias\", \"body.3.weight\", \"body.3.bias\". \n\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"down1.conv_res.weight\", \"down1.conv_res.bias\", \"down1.conv1.weight\", \"down1.conv1.bias\", \"down1.conv2.weight\", \"down1.conv2.bias\", \"down1.bn_res.weight\", \"down1.bn_res.bias\", \"down1.bn_res.running_mean\", \"down1.bn_res.running_var\", \"down1.bn_res.num_batches_tracked\", \"down1.bn1.weight\", \"down1.bn1.bias\", \"down1.bn1.running_mean\", \"down1.bn1.running_var\", \"down1.bn1.num_batches_tracked\", \"down1.bn2.weight\", \"down1.bn2.bias\", \"down1.bn2.running_mean\", \"down1.bn2.running_var\", \"down1.bn2.num_batches_tracked\", \"down2.conv_res.weight\", \"down2.conv_res.bias\", \"down2.conv1.weight\", \"down2.conv1.bias\", \"down2.conv2.weight\", \"down2.conv2.bias\", \"down2.bn_res.weight\", \"down2.bn_res.bias\", \"down2.bn_res.running_mean\", \"down2.bn_res.running_var\", \"down2.bn_res.num_batches_tracked\", \"down2.bn1.weight\", \"down2.bn1.bias\", \"down2.bn1.running_mean\", \"down2.bn1.running_var\", \"down2.bn1.num_batches_tracked\", \"down2.bn2.weight\", \"down2.bn2.bias\", \"down2.bn2.running_mean\", \"down2.bn2.running_var\", \"down2.bn2.num_batches_tracked\", \"down3.conv_res.weight\", \"down3.conv_res.bias\", \"down3.conv1.weight\", \"down3.conv1.bias\", \"down3.conv2.weight\", \"down3.conv2.bias\", \"down3.bn_res.weight\", \"down3.bn_res.bias\", \"down3.bn_res.running_mean\", \"down3.bn_res.running_var\", \"down3.bn_res.num_batches_tracked\", \"down3.bn1.weight\", \"down3.bn1.bias\", \"down3.bn1.running_mean\", \"down3.bn1.running_var\", \"down3.bn1.num_batches_tracked\", \"down3.bn2.weight\", \"down3.bn2.bias\", \"down3.bn2.running_mean\", \"down3.bn2.running_var\", \"down3.bn2.num_batches_tracked\", \"resblock4.conv1.weight\", \"resblock4.conv1.bias\", \"resblock4.conv2.weight\", \"resblock4.conv2.bias\", \"resblock4.bn1.weight\", \"resblock4.bn1.bias\", \"resblock4.bn1.running_mean\", \"resblock4.bn1.running_var\", \"resblock4.bn1.num_batches_tracked\", \"resblock4.bn2.weight\", \"resblock4.bn2.bias\", \"resblock4.bn2.running_mean\", \"resblock4.bn2.running_var\", \"resblock4.bn2.num_batches_tracked\", \"resblock3.conv1.weight\", \"resblock3.conv1.bias\", \"resblock3.conv2.weight\", \"resblock3.conv2.bias\", \"resblock3.bn1.weight\", \"resblock3.bn1.bias\", \"resblock3.bn1.running_mean\", \"resblock3.bn1.running_var\", \"resblock3.bn1.num_batches_tracked\", \"resblock3.bn2.weight\", \"resblock3.bn2.bias\", \"resblock3.bn2.running_mean\", \"resblock3.bn2.running_var\", \"resblock3.bn2.num_batches_tracked\", \"resblock2.conv1.weight\", \"resblock2.conv1.bias\", \"resblock2.conv2.weight\", \"resblock2.conv2.bias\", \"resblock2.bn1.weight\", \"resblock2.bn1.bias\", \"resblock2.bn1.running_mean\", \"resblock2.bn1.running_var\", \"resblock2.bn1.num_batches_tracked\", \"resblock2.bn2.weight\", \"resblock2.bn2.bias\", \"resblock2.bn2.running_mean\", \"resblock2.bn2.running_var\", \"resblock2.bn2.num_batches_tracked\", \"resblock1.conv1.weight\", \"resblock1.conv1.bias\", \"resblock1.conv2.weight\", \"resblock1.conv2.bias\", \"resblock1.bn1.weight\", \"resblock1.bn1.bias\", \"resblock1.bn1.running_mean\", \"resblock1.bn1.running_var\", \"resblock1.bn1.num_batches_tracked\", \"resblock1.bn2.weight\", \"resblock1.bn2.bias\", \"resblock1.bn2.running_mean\", \"resblock1.bn2.running_var\", \"resblock1.bn2.num_batches_tracked\", \"up3.conv.weight\", \"up3.conv.bias\", \"up2.conv.weight\", \"up2.conv.bias\", \"up1.conv.weight\", \"up1.conv.bias\", \"conv_m1.weight\", \"conv_m1.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/battleships_unet.dat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\WPy64-31150\\python-3.11.5.amd64\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for bship_nnet:\n\tMissing key(s) in state_dict: \"body.0.weight\", \"body.0.bias\", \"body.2.weight\", \"body.2.bias\", \"body.3.weight\", \"body.3.bias\". \n\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"down1.conv_res.weight\", \"down1.conv_res.bias\", \"down1.conv1.weight\", \"down1.conv1.bias\", \"down1.conv2.weight\", \"down1.conv2.bias\", \"down1.bn_res.weight\", \"down1.bn_res.bias\", \"down1.bn_res.running_mean\", \"down1.bn_res.running_var\", \"down1.bn_res.num_batches_tracked\", \"down1.bn1.weight\", \"down1.bn1.bias\", \"down1.bn1.running_mean\", \"down1.bn1.running_var\", \"down1.bn1.num_batches_tracked\", \"down1.bn2.weight\", \"down1.bn2.bias\", \"down1.bn2.running_mean\", \"down1.bn2.running_var\", \"down1.bn2.num_batches_tracked\", \"down2.conv_res.weight\", \"down2.conv_res.bias\", \"down2.conv1.weight\", \"down2.conv1.bias\", \"down2.conv2.weight\", \"down2.conv2.bias\", \"down2.bn_res.weight\", \"down2.bn_res.bias\", \"down2.bn_res.running_mean\", \"down2.bn_res.running_var\", \"down2.bn_res.num_batches_tracked\", \"down2.bn1.weight\", \"down2.bn1.bias\", \"down2.bn1.running_mean\", \"down2.bn1.running_var\", \"down2.bn1.num_batches_tracked\", \"down2.bn2.weight\", \"down2.bn2.bias\", \"down2.bn2.running_mean\", \"down2.bn2.running_var\", \"down2.bn2.num_batches_tracked\", \"down3.conv_res.weight\", \"down3.conv_res.bias\", \"down3.conv1.weight\", \"down3.conv1.bias\", \"down3.conv2.weight\", \"down3.conv2.bias\", \"down3.bn_res.weight\", \"down3.bn_res.bias\", \"down3.bn_res.running_mean\", \"down3.bn_res.running_var\", \"down3.bn_res.num_batches_tracked\", \"down3.bn1.weight\", \"down3.bn1.bias\", \"down3.bn1.running_mean\", \"down3.bn1.running_var\", \"down3.bn1.num_batches_tracked\", \"down3.bn2.weight\", \"down3.bn2.bias\", \"down3.bn2.running_mean\", \"down3.bn2.running_var\", \"down3.bn2.num_batches_tracked\", \"resblock4.conv1.weight\", \"resblock4.conv1.bias\", \"resblock4.conv2.weight\", \"resblock4.conv2.bias\", \"resblock4.bn1.weight\", \"resblock4.bn1.bias\", \"resblock4.bn1.running_mean\", \"resblock4.bn1.running_var\", \"resblock4.bn1.num_batches_tracked\", \"resblock4.bn2.weight\", \"resblock4.bn2.bias\", \"resblock4.bn2.running_mean\", \"resblock4.bn2.running_var\", \"resblock4.bn2.num_batches_tracked\", \"resblock3.conv1.weight\", \"resblock3.conv1.bias\", \"resblock3.conv2.weight\", \"resblock3.conv2.bias\", \"resblock3.bn1.weight\", \"resblock3.bn1.bias\", \"resblock3.bn1.running_mean\", \"resblock3.bn1.running_var\", \"resblock3.bn1.num_batches_tracked\", \"resblock3.bn2.weight\", \"resblock3.bn2.bias\", \"resblock3.bn2.running_mean\", \"resblock3.bn2.running_var\", \"resblock3.bn2.num_batches_tracked\", \"resblock2.conv1.weight\", \"resblock2.conv1.bias\", \"resblock2.conv2.weight\", \"resblock2.conv2.bias\", \"resblock2.bn1.weight\", \"resblock2.bn1.bias\", \"resblock2.bn1.running_mean\", \"resblock2.bn1.running_var\", \"resblock2.bn1.num_batches_tracked\", \"resblock2.bn2.weight\", \"resblock2.bn2.bias\", \"resblock2.bn2.running_mean\", \"resblock2.bn2.running_var\", \"resblock2.bn2.num_batches_tracked\", \"resblock1.conv1.weight\", \"resblock1.conv1.bias\", \"resblock1.conv2.weight\", \"resblock1.conv2.bias\", \"resblock1.bn1.weight\", \"resblock1.bn1.bias\", \"resblock1.bn1.running_mean\", \"resblock1.bn1.running_var\", \"resblock1.bn1.num_batches_tracked\", \"resblock1.bn2.weight\", \"resblock1.bn2.bias\", \"resblock1.bn2.running_mean\", \"resblock1.bn2.running_var\", \"resblock1.bn2.num_batches_tracked\", \"up3.conv.weight\", \"up3.conv.bias\", \"up2.conv.weight\", \"up2.conv.bias\", \"up1.conv.weight\", \"up1.conv.bias\", \"conv_m1.weight\", \"conv_m1.bias\". "
     ]
    }
   ],
   "source": [
    "with open('data/battleships_unet.dat', 'rb') as f:\n",
    "    net.load_state_dict(torch.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T11:06:13.776198Z",
     "start_time": "2023-10-29T11:06:13.625937Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(lr=1e-4, params=net.parameters())\n",
    "tau = 0.9\n",
    "bg = batchgen(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-23T14:21:55.441Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ffb6846ce94b6a95ce2d379752402a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m yp \u001b[38;5;241m=\u001b[39m net(x)\n\u001b[0;32m     12\u001b[0m yp \u001b[38;5;241m=\u001b[39m yp \u001b[38;5;241m*\u001b[39m x[:,:,:,[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mx[:,:,:,[\u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(yp\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), yt\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "MSE = nn.MSELoss()\n",
    "losses = []\n",
    "slosses = []\n",
    "\n",
    "for _ in trange(400000):\n",
    "    \n",
    "    # Supervised Learning\n",
    "    x, yt = next(bg)\n",
    "    x, yt = np2t(x, yt)\n",
    "    yp = net(x)\n",
    "    yp = yp * x[:,:,:,[1]] + 0.5 * (1-x[:,:,:,[1]])\n",
    "    raise\n",
    "    loss = criterion(yp.view(-1), yt.view(-1))\n",
    "    loss.backward()\n",
    "    losses += [loss.item()]\n",
    "        \n",
    "    # Semisupervised Learning\n",
    "    x, _ = next(bg)\n",
    "    x = np2t(x)\n",
    "    with torch.no_grad():\n",
    "        y = teacher(x)\n",
    "    x, y = augment(x, y)\n",
    "    y2 = net(x)\n",
    "    sloss = 50*MSE(y, y2)\n",
    "    sloss.backward()\n",
    "    slosses += [sloss.item()]\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    update_mt(teacher, net, tau)\n",
    "    \n",
    "    if len(losses) == 100:\n",
    "        #print(np.mean(losses))\n",
    "        print(np.mean(slosses))\n",
    "        net.losses.append((net.iters, np.mean(losses)))\n",
    "        losses = []\n",
    "        slosses = []\n",
    "        \n",
    "    if net.iters % 100 == 0:\n",
    "        plt.plot(*zip(*net.losses))\n",
    "        plt.ylim([0.58, 0.6])\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        \n",
    "    if net.iters % 1000 == 0:\n",
    "        with open('data/__battleships_dense.dat', 'wb') as f:\n",
    "            torch.save(net.state_dict(), f)\n",
    "        \n",
    "    net.iters += 1\n",
    "        \n",
    "# 120000: tau->0.99, bs->1024, lr->1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T20:30:42.178807Z",
     "start_time": "2023-10-22T20:30:41.668900Z"
    }
   },
   "outputs": [],
   "source": [
    "det = create_detection()\n",
    "#x = torch.from_numpy(encode_x(sea, det)[None,:].astype('float32'))\n",
    "#prob = net(x)[0,:,:,0].detach().cpu().numpy()\n",
    "prob = net.predict(encode_x(sea, det))\n",
    "prob[det > 0] = 0\n",
    "plt.imshow(visualize(sea, det))\n",
    "plt.show()\n",
    "plt.imshow(prob, vmax=1.)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43myp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\WPy64-31150\\python-3.11.5.amd64\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\WPy64-31150\\python-3.11.5.amd64\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:619\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\WPy64-31150\\python-3.11.5.amd64\\Lib\\site-packages\\torch\\nn\\functional.py:3098\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3095\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3096\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[1;32m-> 3098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "criterion(yp, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T19:56:50.782432Z",
     "start_time": "2023-10-22T19:56:50.440Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "sea = njit_create_sea()\n",
    "prob = net.predict(encode_x(sea, det))\n",
    "plt.imshow(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T20:30:53.878231Z",
     "start_time": "2023-10-22T20:30:52.438401Z"
    }
   },
   "outputs": [],
   "source": [
    "sea = np.zeros((10,10))\n",
    "det = np.zeros((10,10))\n",
    "while np.any(1-det):\n",
    "    prob = net.predict(encode_x(sea, det))\n",
    "    prob[det > 0] = 0\n",
    "    ij = np.random.choice(range(100), p=prob.flatten()/np.sum(prob))\n",
    "    i, j = divmod(ij, 10)\n",
    "    det[i,j] = 1\n",
    "    sea[i,j] = 1 if np.random.rand()<prob[i,j] else 0\n",
    "\n",
    "    #plt.imshow(visualize(sea, det))\n",
    "    #plt.show()\n",
    "    #plt.imshow(prob, vmax=1.)\n",
    "    #plt.show()\n",
    "    \n",
    "plt.imshow(visualize(sea, det))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI spielt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T11:08:40.137847Z",
     "start_time": "2023-10-29T11:08:28.632941Z"
    }
   },
   "outputs": [],
   "source": [
    "# gegeben: sea, model\n",
    "det = np.zeros((10,10))\n",
    "##det = create_detection()\n",
    "i,j = [],[]\n",
    "\n",
    "\n",
    "while True:\n",
    "    prob = net.predict(encode_x(sea, det))\n",
    "    prob[det > 0] = 0\n",
    "    percent = 0. if np.sum(det)==0 else 100*np.sum(det*sea)/(np.sum(det)+1e-2)\n",
    "    text = f'Hits: %d, Shots: %d, Percentage: %.1f %%' % (np.sum(det*sea), np.sum(det), percent)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "    ax1.title.set_text('Map')\n",
    "    ax2.title.set_text('Neural Network prediction')\n",
    "    ##fig.text(1/2,0.8, text, fontdict={})\n",
    "    ax1.axis('off')\n",
    "    #ax1.imshow(visualize(sea, det), vmin=0., vmax=3.)\n",
    "    plot_sea(sea, det, ax1)\n",
    "    ax1.scatter(j, i, c='black', alpha=1, s=150)\n",
    "    ax2.axis('off')\n",
    "    ax2.imshow(prob)\n",
    "    #plt.title(text)\n",
    "    plt.show()\n",
    "    \n",
    "    if np.sum(det*sea) >= np.sum(sea): break\n",
    "        \n",
    "    # Welchen Detektieren??\n",
    "    m = prob.argmax()\n",
    "    i, j = m//10, m%10\n",
    "    det[i,j] = 1.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
